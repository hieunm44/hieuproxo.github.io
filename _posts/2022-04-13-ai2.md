---
layout: post
title: "Review sách: Pattern Recognition and Machine Learning"
date: 2022-04-13 23:26:24 +0700
category: AI
---

* __Author:__ Christopher Bishop
* __Originally published:__ 2006
* __Link:__ <a href="https://www.microsoft.com/en-us/research/publication/pattern-recognition-machine-learning/" target="_blank">Pattern Recognition and Machine Learning</a>


# Chapter 1. Introduction
## 1.1. Polynomial Curve Fitting
Phần này giới thiệu bài toán _regression_ cơ bản, là fit  $N$ observations với $N$ corresponding observations. Có hai cách để giải bài toán này:
1. Dùng một polynomial function (lúc này bài toán được gọi là _linear regression_).
2. Dùng _Probability Theory_ (1.2) kết hợp với _Decision Theory_ (1.5).

Phần này trình bày cách thứ nhất, cùng với đó là hiện tượng _over-fitting_ và cách khắc phục dùng _regularlization_.

## 1.2. Probability Theory
Phần này giới thiệu các định nghĩa cơ bản cho lí thuyết xác suất, bao gồm _random variable_, _joint probability_, _marginal probability_, _conditional probability_, _sum rule_, _product rule_, _Bayes' theorem_, _expectation_, _variance_, _covariance_,  _prior probability_, _posterior probability_, _frequentist view_, _Bayesian view_, _maximum likelihood_, _maximum posterior_, và _Gaussian distribution_.

## 1.3. Model Selection
Phần này trình bày kĩ thuật lựa chọn mô hình dùng _cross-validation_.

## 1.4. The Curse of Dimensionality
Phần này trình bày hiện tượng dữ liệu không có tính tổng quát khi số chiều dữ liệu tăng, được gọi là _The curse of dimensionality_.

## 1.5. Decision Theory
Phần này chỉ ra kết hợp Probability theory và Decision Theory sẽ giúp đưa ra optimal decisions trong các trường hợp liên quan đến unvertainty như trong pattern recognition.

## 1.6. Information Theory
Phần này giới thiệu các định nghĩa _entropy_, _differential entropy_, _conditional entropy_,  _relative entropy_ hay _Kullback-Leibler divergence_, _convex function_, _Jensen's inequality_, và _mutual information_.

# Chapter 2. Probability Distributions
## 2.1. Binary Values
Phần này trình bày _Bernoulli distribution_, _Binomial distribution_, giới thiệu tính chất _conjugacy_ khi xây dựng prior và xác định posterior cho tham số mô hình để tránh overfitting trong maximum likelihood, và đưa ra prior _beta distribution_.

## 2.2. Multinomial Variables
Phần này giới thiệu _multinomial distribution_ và conjugate prior _Dirichlet distribution_

## 2.3. The Gaussian Distribution
Phần này trình bày kĩ hơn Gaussian distribution, giới thiệu _central limit theorem_, trình bày geometrical form của Gaussian distribution, các hạn chế của multivariate Gaussian distribution và cách khắc phục (trong đó có nhắc đến _mixtures of Gaussian_). Phần này tiếp tục trình bày _conditional Gaussian distribution_, _marginal Gaussian distribution_ (gọi chung là _paritioned Gaussians_), Bayes' theorem for Gaussian variables, maximum likelihood for the Gaussian và tính chất _sufficient statistics_. Tiếp theo phần này trình bày về sequential estimation cho chuỗi các data points, Bayesian inference for the Gaussian, _Student's t-distribution_ (là cộng dồn vô hạn các Gaussian distributions có cùng mean nhưng khác precisions, được gọi là _infinite mixture of Gaussians_), tính chất quan trọng của t-distribution là _robustness_ (ít nhạy cảm với nhiễu hơn so với Gaussian), và cuối cùng là _mixture of Gaussians_.

## 2.4. The Exponential Family
Phần này chỉ ra các phân phối từ trước đến nay (trừ Gaussian mixture) đều là các trường hợp cụ thể của _exponential family_, sau đó xét một số phân phối đã biết, bao gồm Bernoulli distribution, multinomial distribution, và Gaussian distribution. Sau đó phần này giới thiệu _noninformative prior_ dùng khi ta biết rất ít về dạng của distribution cần tìm, trình bày hai ví dụ của noninformative prior với các tham số tương ứng là _location parameter_ (VD: $\mu$ trong Gaussian) và _scale parameter_ (VD: $\sigma$ trong Gaussian); các tính chất tương ứng là _translation invariance_ và _scale invariance_.

## 2.5. Nonparametric Methods
Từ trước đến nay đã xét các phân phối phụ thuộc vào các parameters mà cần được xác định từ data set, đây được gọi là _parametric approach_. Phương pháp này có hạn chế là nếu density được chọn là poor model của phân phối tạo ra dữ liệu, thì kết quả là poor predictive performance. Phần này sẽ trình bày các _nonparametric approaches_, đầu tiên là giới thiệu _histogram method_, tiếp theo là kernel density estimators (gồm _kernel method_ và _nearest-neighbor method_).

_Bài viết này vẫn tiếp tục được cập nhật._
